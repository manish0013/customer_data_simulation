{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto\n",
    "from boto.s3.key import Key\n",
    "import requests\n",
    "key = 'enter s3 key'\n",
    "secret = 'enter s3 secret'\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_boolean():\n",
    "    return bool(random.getrandbits(1))\n",
    "\n",
    "def generate_number(minx=0, maxx=100, is_int=False):\n",
    "    return random.randint(minx, maxx) if is_int else random.uniform(minx, maxx)\n",
    "\n",
    "def generate_string_data(length):\n",
    "    return ''.join(random.sample(string.ascii_letters, length))\n",
    "\n",
    "def generate_hash(length):\n",
    "    return ''.join(random.sample(string.ascii_letters + string.digits, length))\n",
    "\n",
    "def generate_list_hash(counts, length):\n",
    "    return [\n",
    "        generate_hash(length)\n",
    "        for _ in range(counts)\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_array_data_type(item_type, n_items=1, minx=0, maxx=100, length=10, item_predefined_values=[],\n",
    "                            k = 9, theta = 0.5,mu = 0,sigma = 0):\n",
    "    if item_type == \"string\":\n",
    "        return [generate_string_data(length) for _ in range(n_items)]\n",
    "    elif item_type == \"integer\":\n",
    "        return [generate_number(minx, maxx, is_int=True) for _ in range(n_items)]\n",
    "    elif item_type in {\"float\", \"number\"}:\n",
    "        return [generate_number(minx, maxx, is_int=False) for _ in range(n_items)]\n",
    "    elif item_type == \"boolean\":\n",
    "        return [generate_boolean() for _ in range(n_items)]\n",
    "    elif item_type == \"enum\":\n",
    "        return [random.choice(item_predefined_values) for _ in range(n_items)]\n",
    "    elif item_type == \"gamma\":\n",
    "        return [round(np.random.gamma(k,theta)) for _ in range(n_items)]\n",
    "    elif item_type == \"normal\":\n",
    "        return [round(np.random.normal(mu,sigma)) for _ in range(n_items)]\n",
    "    else:\n",
    "        raise UserError(\"{} is not supported\".format(item_type))\n",
    "        \n",
    "def generate_dates(start_date, end_date, size):\n",
    "    \"\"\"\n",
    "    Generate random dates within range between start and end.\n",
    "    Adapted from: https://stackoverflow.com/a/50668285\n",
    "    \"\"\"\n",
    "    # Unix timestamp is in nanoseconds by default, so divide it by\n",
    "    # 24*60*60*10**9 to convert to days.\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    divide_by = 24 * 60 * 60 * 10 ** 9\n",
    "    start_u = start.value // divide_by\n",
    "    end_u = end.value // divide_by\n",
    "    return pd.to_datetime(np.random.randint(start_u, end_u, size), unit=\"D\")\n",
    "        \n",
    "def generate_predefined_list(size, item_predefined_values, p=None):\n",
    "    \"\"\"Generate n-length ndarray of genders.\"\"\"\n",
    "    if not p:\n",
    "        # default probabilities\n",
    "        p = (0.33, 0.33, 0.34)\n",
    "    return np.random.choice(item_predefined_values, size=size, p=p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class synthetic_data_simulation():\n",
    "    \"\"\"\n",
    "    to simulate transaction, demographics and campaign data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,customer_id,size,transaction_file,gender = ['Male','Female','Unknown'],gender_prob = [0.40,0.45,0.15],\n",
    "                 age = ['< 15', '16 - 19', '20 - 29', '30 - 39', '40 - 49', '50 - 59', '60+','Unknown'],\n",
    "                 age_prob = [0.01, 0.03, 0.28, 0.10, 0.30, 0.08, 0.05, 0.15], loyalty_member_flag = [0,1],\n",
    "                 loyalty_member_flag_prob = [0.08,0.92], loyalty_member_program = [\"Member\",\"Insider\",\n",
    "                \"Influencer\", \"Ambassador\"],loyalty_member_program_prob = [0.06, 0.09, 0.23, 0.62],\n",
    "                 income_group = [\"Less than $49,999\", \"$50,000 - $74,999\", \"$75,000 - $99,999\",\n",
    "                \"$100,000 - $149,999\",\"$150,000 - $199,999\", \"$200,000+\", \"Unknown\"], \n",
    "                  income_group_prob = [0, 0.01, 0.05, 0.17, 0.22, 0.45, 0.10],store_visit_k = 14,\n",
    "                  store_visit_theta = 0.5,review_k = 8, review_theta = 0.5, client_segment = \"VIP\",\n",
    "                 attempted_segment_split =  \"VIP\", \n",
    "                  signup_date_min = '2015-12-01',signup_date_max = '2017-12-31',\n",
    "                 \n",
    "                tx_k = 12, tx_theta = 0.5,order_value_m = 2750,order_value_sd =2750/5,\n",
    "                             scale_2018_factor = 0.95,scale_2020_factor = 1.05,\n",
    "                 \n",
    "                n_campaign_cust = 15000,campaign ='Fall19 Fashion and NYC Campaign',\n",
    "                offer_id = [1,2,3,4,5],offer_name =  ['3 for 2 Accessories', 'Relaunch Offer â€“ 25% Off',\n",
    "                '3 for $ 250 Chinos','Free gift on your Birthday','Earn more points'],\n",
    "                offer_prob = [0.25,0.2,0.15,0.10,0.30],offer_reward = [50,50,50,50,50],\n",
    "                top_2_offer = [1,5],uplift_feature = ['gender','age_group'],\n",
    "                uplift_feature_value = ['Female','40-39'],uplift_value = [.20,.15],base_uplift = 0.4,\n",
    "                campaign_launch_date = '2019-02-01',campaign_file = None,item_list = None):\n",
    "\n",
    "        \"\"\"\"\n",
    "        This class generates synthetic transaction data at customer level\n",
    "        size : # customers \n",
    "        customer_id : a list of unique customer ids belonging to these customers\n",
    "        gender : list of genders\n",
    "        gender_prob : list of probabilities of gender distribution in same order as gender\n",
    "        age : list of age buckets\n",
    "        age_prob : list of probabilities of age distribution in same order as age buckets\n",
    "        loyalty_member_flag : flag 1 if customer is part of loyalty program\n",
    "        loyalty_member_flag_prob : probability distribution of loyalty member flag\n",
    "        loyalty_member_program : list of loyalty programs by business\n",
    "        loyalty_member_program_prob : probability distribution of loyalty member programs in same order\n",
    "        income_group : list of income groups\n",
    "        income_group_prob : list of probabilities of income distribution in same order as income group\n",
    "        store_visit_k : shape parameter K for store visits (gamma distribution)\n",
    "        store_visit_theta : shape parameter theta for store visits (gamma distribution)\n",
    "        review_k : shape parameter K for reviews (gamma distribution)\n",
    "        review_theta : shape parameter theta for reviews (gamma distributi \n",
    "        client_segment : one of \"Premium\", \"VIP\", \"Need Based\", \"Promising\", \"Gifters\"\n",
    "        attempted segment split : sub segment for e.g. \"Luxury Event Seekers\", \"Designer Brand Seekers\" etc.\n",
    "        sign_up_date_min : min signup date\n",
    "        sign_up_date_max : max signup date of customers\n",
    "\n",
    "        tx_k : shape parameter K for # transactions by customer (gamma distribution)\n",
    "        tx_theta : shape parameter theta for # transaction by customer (gamma distributi \n",
    "        order_value_m : mean order value (normal distribution) (year 2019)\n",
    "        order_value_sd : sd of order value (normal distribution) (year 2019)\n",
    "        scale_2018_factor : scaling up or down AOV for year 2018 \n",
    "        scale_2020_factor : scaling up or down AOV for year 2020\n",
    "\n",
    "        returns : customer transaction data\n",
    "\n",
    "        n_campaign_cust: # customers part of any campaign\n",
    "        campaign : name of campaign (only 1 is supported)\n",
    "        offer_id : list of offers part of the campaign\n",
    "        offer_name : name of offers\n",
    "        offer_prob : prob dist of offers\n",
    "        offer_reward : cost of each offer\n",
    "        top_2_offer : list of top 2 offers for uplift purposes\n",
    "        uplift_feature_value : important features to predict uplift\n",
    "        uplift_value : value of uplift (in %)\n",
    "        campaign_launch_date : launch of campaing (first date of any month)\n",
    "\n",
    "        \"\"\"    \n",
    "        self.size = size\n",
    "        self.customer_id = customer_id\n",
    "        self.gender = gender\n",
    "        self.gender_prob =gender_prob\n",
    "        self.age = age\n",
    "        self.age_prob = age_prob\n",
    "        self.loyalty_member_flag = loyalty_member_flag\n",
    "        self.loyalty_member_flag_prob = loyalty_member_flag_prob\n",
    "        self.loyalty_member_program = loyalty_member_program\n",
    "        self.loyalty_member_program_prob = loyalty_member_program_prob\n",
    "        self.income_group = income_group\n",
    "        self.income_group_prob = income_group_prob\n",
    "        self.store_visit_k = store_visit_k\n",
    "        self.store_visit_theta = store_visit_theta\n",
    "        self.review_k = review_k\n",
    "        self.review_theta = review_theta\n",
    "        self.client_segment = client_segment\n",
    "        self.attempted_segment_split = attempted_segment_split\n",
    "        self.signup_date_min = signup_date_min\n",
    "        self.signup_date_max = signup_date_max\n",
    "        \n",
    "        self.tx_k = tx_k\n",
    "        self.tx_theta = tx_theta\n",
    "        self.order_value_m = order_value_m\n",
    "        self.order_value_sd =order_value_sd\n",
    "        self.scale_2018_factor = scale_2018_factor\n",
    "        self.scale_2020_factor = scale_2020_factor\n",
    "        self.n_campaign_cust = n_campaign_cust\n",
    "        self.campaign = campaign\n",
    "        self.offer_id = offer_id\n",
    "        self.offer_name =offer_name\n",
    "        self.offer_prob = offer_prob\n",
    "        self.offer_reward = offer_reward\n",
    "        self.top_2_offer = top_2_offer\n",
    "        self.uplift_feature = uplift_feature\n",
    "        self.uplift_feature_value = uplift_feature_value\n",
    "        self.uplift_value = uplift_value\n",
    "        self.base_uplift = base_uplift\n",
    "        self.campaign_launch_date = campaign_launch_date\n",
    "        self.item_list = item_list\n",
    "        self.transaction_file = transaction_file\n",
    "        self.campaign_file = campaign_file\n",
    "    \n",
    "    def generate_customer_data(self):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        df = pd.DataFrame(columns=['customer_id', 'gender', 'age_group', 'city', \n",
    "                                   'loyalty_member_flag', 'loyalty_group', 'income_group',\n",
    "                                   'store_visits', 'reviews', 'client_segment', 'signup_date',\n",
    "                                   'attempted_segment_split'])\n",
    "\n",
    "        # Below proportions are tuned to Decliner Premium Designer Brand Seeker sub-segments\n",
    "        df['customer_id'] = self.customer_id\n",
    "        df['gender'] = generate_predefined_list(self.size,self.gender,self.gender_prob)\n",
    "\n",
    "        df['age_group'] = generate_predefined_list(self.size,self.age,self.age_prob)\n",
    "\n",
    "        city = pd.read_csv('C:/Users/mm13690/Documents/codes/p_ai/input/us_city.csv')\n",
    "        city = city.drop_duplicates('city').head()\n",
    "        city['p'] = city['pop']/city['pop'].sum()\n",
    "\n",
    "        df['city'] = generate_predefined_list(self.size,city['city'].tolist(),city['p'].tolist())\n",
    "\n",
    "        # join state\n",
    "\n",
    "\n",
    "        df = df.merge(city[['city','state']], on = 'city',how = 'inner')\n",
    "\n",
    "\n",
    "        df['loyalty_member_flag'] = generate_predefined_list(self.size, self.loyalty_member_flag,\n",
    "                                                             self.loyalty_member_flag_prob)\n",
    "\n",
    "\n",
    "        df['loyalty_group'] = df.loyalty_member_flag.apply(\n",
    "            lambda x: np.random.choice(self.loyalty_member_program,\n",
    "                                       size=1,\n",
    "                                       p=self.loyalty_member_program_prob)[0]\n",
    "            if x == 1 else None\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        df['income_group'] = generate_predefined_list(self.size,self.income_group,self.income_group_prob)\n",
    "\n",
    "        df['store_visits'] = generate_array_data_type(\"gamma\", n_items=self.size, k = self.store_visit_k,\n",
    "                                                      theta= self.store_visit_theta)\n",
    "\n",
    "        df['reviews'] = generate_array_data_type(\"gamma\", n_items=self.size, k= self.review_k, theta= self.review_theta)\n",
    "        df['client_segment'] = self.client_segment\n",
    "        df['attempted_segment_split'] = self.attempted_segment_split\n",
    "        df['signup_date'] = generate_dates(self.signup_date_min, self.signup_date_max, size=self.size) # all customers have signup before 2018\n",
    "        end_time = datetime.datetime.now()\n",
    "        print(\"Time taken to create demographic data having {} customers {}\".format(df.shape[0],end_time - start_time))\n",
    "        return df\n",
    "    \n",
    "    def generate_transaction_data(self,df):\n",
    "        \"\"\"\n",
    "        df :  customer demographics data\n",
    "\n",
    "        \"\"\"\n",
    "        global get_transaction\n",
    "        start_time = datetime.datetime.now()\n",
    "        temp = pd.DataFrame(columns=['customer_id','order_value','order_date'])\n",
    "        order_value = []\n",
    "        order_date = []\n",
    "        customer_id = []\n",
    "        item_id = []\n",
    "        customers = df.customer_id.tolist()\n",
    "        for customer in customers:\n",
    "            \n",
    "            \n",
    "            n_tx = round(np.random.gamma(self.tx_k,self.tx_theta))\n",
    "            # enter mean and sd of Avg order value for this segment\n",
    "\n",
    "            # simulate data - 2019\n",
    "            _order_value = generate_array_data_type(\"normal\", n_items=n_tx, mu = self.order_value_m, sigma = self.order_value_sd)\n",
    "            _order_date = generate_dates('2019-01-01', '2019-12-31', size=n_tx)\n",
    "            _item_id = generate_array_data_type(\"enum\", n_items=n_tx,item_predefined_values=self.item_list)\n",
    "            order_value.extend(_order_value)\n",
    "            order_date.extend(_order_date)\n",
    "            item_id.extend(_item_id)\n",
    "            _customer_id = generate_array_data_type(\"enum\", n_items=n_tx,item_predefined_values=[customer])\n",
    "            customer_id.extend(_customer_id)\n",
    "\n",
    "            # simulate data - 2018\n",
    "            _order_value = [ x*np.random.normal(self.scale_2018_factor,self.scale_2018_factor/8) for x in _order_value]  # x % decline/incline in 2018\n",
    "            _order_date = generate_dates('2018-01-01', '2018-12-31', size=n_tx)\n",
    "            _item_id = generate_array_data_type(\"enum\", n_items=n_tx,item_predefined_values=self.item_list)\n",
    "            order_value.extend(_order_value)\n",
    "            order_date.extend(_order_date)\n",
    "            item_id.extend(_item_id)\n",
    "\n",
    "            _customer_id = generate_array_data_type(\"enum\", n_items=n_tx,item_predefined_values=[customer])\n",
    "            customer_id.extend(_customer_id)\n",
    "\n",
    "            # simulate data - 2020\n",
    "            n_tx = round(n_tx/2)\n",
    "            _order_value = [ x*np.random.normal(self.scale_2020_factor,self.scale_2020_factor/8) for x in _order_value][:n_tx] \n",
    "            _order_date = generate_dates('2020-01-01', '2020-12-31', size=n_tx)\n",
    "            _item_id = generate_array_data_type(\"enum\", n_items=n_tx,item_predefined_values=self.item_list)\n",
    "            order_value.extend(_order_value)\n",
    "            order_date.extend(_order_date)\n",
    "            item_id.extend(_item_id)\n",
    "\n",
    "            _customer_id = generate_array_data_type(\"enum\", n_items=n_tx,item_predefined_values=[customer])\n",
    "            customer_id.extend(_customer_id)\n",
    "\n",
    "\n",
    "\n",
    "        temp['customer_id'] = customer_id\n",
    "        temp['order_value'] = order_value\n",
    "        temp['order_date'] = order_date\n",
    "        temp['item_id'] = item_id\n",
    "\n",
    "        customer_transaction = temp.merge(df,on = 'customer_id', how = 'left')  \n",
    "\n",
    "        customer_transaction['month'] = pd.to_datetime(customer_transaction['order_date']).dt.month\n",
    "        customer_transaction['year'] = pd.to_datetime(customer_transaction['order_date']).dt.year\n",
    "        end_time = datetime.datetime.now()\n",
    "        print(\"Time taken tp create trasaction data having {} customer {}\".format(df.shape[0],end_time - start_time))\n",
    "        return customer_transaction\n",
    "    \n",
    "\n",
    "    def generate_campaign_data(self,df,customer_transaction):\n",
    "        \"\"\"\n",
    "        df: customer demographics data\n",
    "        customer_transaction: transaction data\n",
    "        n_campaign_cust: # customers part of any campaign\n",
    "        campaign : name of campaign (only 1 is supported)\n",
    "        offer_id : list of offers part of the campaign\n",
    "        offer_name : name of offers\n",
    "        offer_prob : prob dist of offers\n",
    "        offer_reward : cost of each offer\n",
    "        top_2_offer : list of top 2 offers for uplift purposes\n",
    "        uplift_feature_value : important features to predict uplift\n",
    "        uplift_value : value of uplift (in %)\n",
    "        campaign_launch_date : launch of campaing (first date of any month)\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        campaign_customer = df.sample(n = self.n_campaign_cust)\n",
    "        campaign_customer['campaign'] = self.campaign\n",
    "        offer_data = pd.DataFrame({'offer_id': self.offer_id,\n",
    "                                  'offer_name': self.offer_name,\n",
    "                                  'reward':self.offer_reward})\n",
    "\n",
    "        campaign_customer['offer_id'] = generate_predefined_list(self.n_campaign_cust,self.offer_id,self.offer_prob)\n",
    "        campaign_customer = campaign_customer.merge(offer_data[['offer_id','offer_name']], on = 'offer_id', how = 'left')\n",
    "\n",
    "        # simulate uplift by static features\n",
    "        campaign_customer['uplift'] = .04\n",
    "        campaign_customer['uplift'][(campaign_customer[self.uplift_feature[0]] == self.uplift_feature_value[0]) & (campaign_customer['offer_id'] == self.top_2_offer[0])] = self.uplift_value[0]\n",
    "        campaign_customer['uplift'][(campaign_customer[self.uplift_feature[0]] == self.uplift_feature_value[0]) & (campaign_customer['offer_id'] == self.top_2_offer[1])] = self.uplift_value[1]\n",
    "        campaign_customer['offer_launch'] = self.campaign_launch_date\n",
    "        campaign_customer['month'] = pd.to_datetime(campaign_customer['offer_launch']).dt.month\n",
    "        campaign_customer['year'] = pd.to_datetime(campaign_customer['offer_launch']).dt.year\n",
    "\n",
    "        campaign_customer_converted = campaign_customer.merge(customer_transaction[['customer_id','item_id','month','year']].drop_duplicates(),on = ['customer_id','month','year'], how = 'inner')\n",
    "        campaign_customer_converted.drop_duplicates('customer_id',inplace = True )\n",
    "        campaign_customer_converted['offer_converted'] = 1\n",
    "#         print(\"check1\",campaign_customer.shape)\n",
    "        campaign_customer = campaign_customer.merge(campaign_customer_converted[['customer_id','item_id','offer_converted']], on = 'customer_id',how = 'left')\n",
    "        campaign_customer.reset_index(drop = True,inplace = True)\n",
    "#         print(\"check2\",campaign_customer.shape)\n",
    "#         print(campaign_customer.tail())\n",
    "        campaign_customer.loc[campaign_customer['item_id'].isna(),'item_id']   = generate_array_data_type(\"enum\", n_items=campaign_customer[campaign_customer['item_id'].isna()].shape[0],item_predefined_values=self.item_list)\n",
    "#         print(\"check3\",campaign_customer.shape)        \n",
    "        campaign_customer.fillna(0, inplace = True)\n",
    "#         print(\"check4\",campaign_customer.shape) \n",
    "        campaign_customer['offer_sent'] = 1\n",
    "        \n",
    "\n",
    "        customer_transaction = customer_transaction.merge(campaign_customer[['customer_id','uplift',\n",
    "                                                        'month','year','offer_sent','offer_id','offer_name','campaign','offer_converted']], on = \n",
    "                                                         ['customer_id','month','year'], how = 'left')\n",
    "\n",
    "        customer_transaction.fillna(0,inplace = True)\n",
    "\n",
    "\n",
    "        # update order value with uplift values and check incremental revenue\n",
    "        month = pd.to_datetime(self.campaign_launch_date).month\n",
    "        year = pd.to_datetime(self.campaign_launch_date).year\n",
    "    #     print(customer_transaction.order_value.sum())\n",
    "        def update_order(x):\n",
    "            if (x['month'] == month) & (x['year'] == year):\n",
    "                if x['offer_sent'] ==1:\n",
    "                    x['order_value'] = x['order_value']*(1+x['uplift'])\n",
    "            return x['order_value']\n",
    "\n",
    "        customer_features = df.columns\n",
    "        customer_transaction['order_value'] =  customer_transaction.apply(update_order,axis = 1)\n",
    "        customer_transaction_agg = customer_transaction[(customer_transaction['month'] == month) & (customer_transaction['year'] == year)].groupby(list(customer_features)).agg({'order_value': 'sum'}).reset_index()\n",
    "        \n",
    "        campaign_customer = campaign_customer.merge(customer_transaction_agg[['customer_id','order_value']],on = 'customer_id',how = 'left')\n",
    "        cust_ids_no_campaign = np.setdiff1d(customer_transaction_agg.customer_id,campaign_customer.customer_id).tolist()\n",
    "\n",
    "        control_customer = customer_transaction_agg[customer_transaction_agg.customer_id.isin(cust_ids_no_campaign)]\n",
    "        \n",
    "        campaign_customer = campaign_customer.append(control_customer,ignore_index = True)\n",
    "#         print(\"check5\",campaign_customer.shape)\n",
    "#         print(campaign_customer['item_id'].tail())\n",
    "        campaign_customer.loc[campaign_customer['item_id'].isna(),'item_id']   = generate_array_data_type(\"enum\", n_items=campaign_customer[campaign_customer['item_id'].isna()].shape[0],item_predefined_values=self.item_list)\n",
    "        campaign_customer.fillna(0,inplace = True)\n",
    "#         print(\"check6\",campaign_customer.shape)\n",
    "        customer_transaction.drop(columns=['uplift'], inplace = True)\n",
    "    #     print(customer_transaction.order_value.sum())\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "        print(\"Time taken to create campaign data for {} customer {}\".format(df.shape[0],end_time - start_time))\n",
    "\n",
    "        return customer_transaction,campaign_customer\n",
    "\n",
    "    \n",
    "    def write_to_s3(self,customer_transaction,campaign_customer = None):\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # write data to s3\n",
    "\n",
    "        bytes_to_write = customer_transaction.to_csv(None).encode()\n",
    "        fs = s3fs.S3FileSystem(key=key, secret=secret)\n",
    "        with fs.open('s3://zs-atp-pzai-general/data/data_for_integrated_story/premium/' + str(self.transaction_file) +'.csv', 'wb') as f:\n",
    "            f.write(bytes_to_write)\n",
    "        if campaign_customer is None:\n",
    "            pass\n",
    "        else:\n",
    "            bytes_to_write = campaign_customer.to_csv(None).encode()\n",
    "            fs = s3fs.S3FileSystem(key=key, secret=secret)\n",
    "            with fs.open('s3://zs-atp-pzai-general/data/data_for_integrated_story/premium/' + str(self.campaign_file) +'.csv', 'wb') as f:\n",
    "                f.write(bytes_to_write)\n",
    "            \n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "        print(\"Time taken for writing data to s3 with {} records {}\".format(customer_transaction.shape[0],end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello world\n"
    }
   ],
   "source": [
    "# the list of items to select from transactions\n",
    "random.seed(42)\n",
    "# read a list of customer ids\n",
    "\n",
    "df = pd.read_csv('C:/Users/mm13690/Documents/codes/p_ai/input/premium_customer_ids.csv')\n",
    "premium_customer_ids = df.customer_ids.tolist()\n",
    "\n",
    "# generate a list of item ids\n",
    "item_list = [i for i in range(1,53433)]\n",
    "\n",
    "##for designer brand seekers\n",
    "# item_list = [i for i in range(35184,39499)]\n",
    "# random_item_list = [i for i in range(1,10000)]\n",
    "# random_item_list = np.random.choice(random_item_list,size = 1500)\n",
    "# item_list.extend(random_item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.seed(42)\n",
    "\n",
    "premium_customer_ids_chunks = np.array_split(premium_customer_ids,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create data for designer brand seekers\n",
    "designer_brand_seekers = premium_customer_ids_chunks[0]\n",
    "# loyalists_customer_id = _list\n",
    "transaction_file = 'dbs_transaction'\n",
    "campaign_file = 'dbs_campaign'\n",
    "\n",
    "obj = synthetic_data_simulation(customer_id=designer_brand_seekers,size = len(designer_brand_seekers),transaction_file = transaction_file,\n",
    "                campaign_file = campaign_file,item_list= item_list,gender = ['Male','Female','Unknown'],\n",
    "                gender_prob = [0.18,0.71,0.11],\n",
    "                age = ['< 15', '16 - 19', '20 - 29', '30 - 39', '40 - 49', '50 - 59', '60+','Unknown'],\n",
    "                age_prob = [0.01, 0.03, 0.24, 0.31, 0.14, 0.08, 0.02, 0.17],\n",
    "                loyalty_member_flag = [0,1],\n",
    "                loyalty_member_flag_prob = [0.12,0.88],\n",
    "                loyalty_member_program = [\"Member\",\"Insider\",\"Influencer\", \"Ambassador\"],\n",
    "                loyalty_member_program_prob = [0.16, 0.24, 0.26, 0.34],\n",
    "                income_group = [\"Less than $49,999\", \"$50,000 - $74,999\",\n",
    "                \"$75,000 - $99,999\",\"$100,000 - $149,999\",\"$150,000 - $199,999\", \"$200,000+\", \"Unknown\"], \n",
    "                income_group_prob = [0, 0.0, 0.05, 0.10, 0.15, 0.60, 0.10],\n",
    "                store_visit_k = 20,store_visit_theta = 0.5,\n",
    "                review_k = 6, review_theta = 0.5,\n",
    "                client_segment = \"Premium\",\n",
    "                attempted_segment_split =  \"Designer Brand Seekers\", \n",
    "                signup_date_min = '2015-12-01',signup_date_max = '2017-12-31',\n",
    "\n",
    "                tx_k = 10, tx_theta = 0.5,order_value_m = 1186,order_value_sd =1186/5,\n",
    "                scale_2018_factor = 1.04,scale_2020_factor = 0.95,\n",
    "                \n",
    "                n_campaign_cust = 15000,campaign ='Valentines Day Gemstone Jewelry Collection',\n",
    "                offer_id = [1,2,3,4,5,6,7,8],offer_name =  ['3 for 2 Accessories', 'Relaunch Offer â€“ 25% Off',\n",
    "                '3 for $ 250 Chinos','Free gift on your Birthday','Earn more points','Designer Suits $199.99',\n",
    "                'Dress shirt and ties extra 20% off','First to shop select brands'],\n",
    "                offer_prob = [0.125,0.125,0.125,0.125,0.125,0.125,0.125,0.125],offer_reward = [50,50,50,50,50,50,50,50],\n",
    "                top_2_offer = [3,6],\n",
    "                uplift_feature = ['loyalty_group','age_group'],\n",
    "                uplift_feature_value = [\"Ambassador\",'60+'],\n",
    "                uplift_value = [.20,.15],base_uplift = 0.04,\n",
    "                campaign_launch_date = '2019-02-01')\n",
    "\n",
    "df = obj.generate_customer_data()\n",
    "customer_transaction = obj.generate_transaction_data(df)\n",
    "customer_transaction, campaign_customer = obj.generate_campaign_data(df,customer_transaction)\n",
    "obj.write_to_s3(customer_transaction, campaign_customer = campaign_customer)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}